{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transforms=None, pca=None):\n",
    "        iter = 0\n",
    "        for path in csv_path:\n",
    "            if iter == 0:\n",
    "                self.data = pd.read_csv(path).query(\"Label<8\")\n",
    "            else:\n",
    "                self.data = self.data.append(pd.read_csv(path).query(\"Label<8\"))\n",
    "            iter += 1\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "#        self.data = self.data.query(\"Label<8\")\n",
    "        self.labels = np.asarray(self.data.iloc[:, 1])\n",
    "        self.transforms = transforms\n",
    "        self.pca = pca\n",
    "        self.imgs = []\n",
    "        for index in range(self.data.iloc[:, 0].size):\n",
    "            img_x = Image.open(images_folder + self.data.iloc[:, 0][index])\n",
    "            img_x = img_x.convert('L')\n",
    "            img_x = np.array(img_x).reshape(1,-1)[0]\n",
    "            self.imgs.append(img_x)\n",
    "        self.imgs = np.array(self.imgs)\n",
    "        # PCA tranform the images\n",
    "        self.imgs = pca.transform(self.imgs)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]\n",
    "        img = self.imgs[index].reshape(30,30)\n",
    "        '''\n",
    "        img = Image.open(images_folder + self.data.iloc[:, 0][index])\n",
    "        img = img.convert('L')\n",
    "        # edge detection\n",
    "        # img = img.filter(ImageFilter.FIND_EDGES)\n",
    "        '''\n",
    "        # 将图像转换成 tensor\n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img)\n",
    "            # 返回图像及其 label\n",
    "        \n",
    "        return (img_as_tensor, single_image_label)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "batch_size = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [\"train_subset0.csv\", \"train_subset1.csv\", \"train_subset2.csv\", \"train_subset3.csv\", \"train_subset4.csv\"]\n",
    "test_sets = [\"val_subset0.csv\", \"val_subset1.csv\", \"val_subset2.csv\", \"val_subset3.csv\", \"val_subset4.csv\"]\n",
    "images_folder = \"./images/\"\n",
    "labels_folder = \"./labels/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dir = os.path.join(os.getcwd(), \"labels\", train_sets[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Filename  Label\n",
      "0     20170410-123553-0.jpg      0\n",
      "1     20171109-072611-1.jpg      5\n",
      "2     20170714-115750-2.jpg      1\n",
      "3     20171113-144443-3.jpg      6\n",
      "4     20171102-120225-2.jpg      2\n",
      "...                     ...    ...\n",
      "5039  20171025-082241-2.jpg      3\n",
      "5040  20171121-084619-1.jpg      6\n",
      "5041  20170727-140127-1.jpg      4\n",
      "5042  20170906-113728-1.jpg      3\n",
      "5043  20170217-095330-0.jpg      7\n",
      "\n",
      "[5044 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "label__ = pd.read_csv(label_dir).query(\"Label<8\").reset_index(drop=True)\n",
    "print(label__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15  60  71 ...  39  58  62]\n",
      " [  5  97  53 ...  83  82  88]\n",
      " [ 52  82  25 ... 111  72  66]\n",
      " ...\n",
      " [ 93 113 120 ... 110 132 116]\n",
      " [125 118 102 ... 113 132 156]\n",
      " [140 126 109 ...  61  63 110]]\n",
      "[ 15  60  71 ...  61  63 110]\n",
      "(200, 65536)\n",
      "(200, 150)\n",
      "(200, 65536)\n",
      "[[244   8  22 ...  24  18  23]\n",
      " [255 238  12 ...  30  20  33]\n",
      " [252 255  12 ...  21   3  21]\n",
      " ...\n",
      " [ 13  21  15 ...  15  15  28]\n",
      " [255  12  19 ...   4  20  46]\n",
      " [  5  19  12 ...   4  31  45]]\n"
     ]
    }
   ],
   "source": [
    "img__ = Image.open(images_folder + label__.iloc[:, 0][1]) \n",
    "img__ = img__.convert('L')\n",
    "#img__.show()\n",
    "imageWithEdges = img__.filter(ImageFilter.FIND_EDGES)\n",
    "#imageWithEdges.show()\n",
    "img__ = np.array(img__)\n",
    "#img__ = img__.view(-1, 256 * 256)\n",
    "print( img__ )\n",
    "print( img__.reshape(1,-1)[0] )\n",
    "\n",
    "images_samples = []\n",
    "labels_samples = []\n",
    "\n",
    "for index in range(200):\n",
    "    img_x = Image.open(images_folder + label__.iloc[:, 0][index])\n",
    "    img_x = img_x.convert('L')\n",
    "    img_x = np.array(img_x).reshape(1,-1)[0]\n",
    "    images_samples.append(img_x)\n",
    "    labels_samples.append(label__.iloc[:, 1][index])\n",
    "\n",
    "images_samples = np.array(images_samples)\n",
    "print(images_samples.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "pca = PCA(n_components=150).fit(images_samples)\n",
    "lda = LinearDiscriminantAnalysis(n_components=7).fit(images_samples, labels_samples)\n",
    "\n",
    "new_imgs = pca.transform(images_samples)\n",
    "rev_imgs = pca.inverse_transform(new_imgs)\n",
    "\n",
    "print(new_imgs.shape)\n",
    "print(rev_imgs.shape)\n",
    "\n",
    "print(rev_imgs[0].reshape(256,256).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_img__ = Image.fromarray(rev_imgs[0].reshape(256,256).astype('uint8'))\n",
    "\n",
    "rev_img__.show()\n",
    "\n",
    "img_x = Image.open(images_folder + label__.iloc[:, 0][0])\n",
    "img_x = img_x.convert('L')\n",
    "img_x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePCA(train_path):\n",
    "    labels = pd.read_csv(train_path).query(\"Label<8\").reset_index(drop=True)\n",
    "    train_images = []\n",
    "    for index in range(labels.iloc[:, 0].size):\n",
    "        img_x = Image.open(images_folder + label__.iloc[:, 0][index])\n",
    "        img_x = img_x.convert('L')\n",
    "        img_x = np.array(img_x).reshape(1,-1)[0]\n",
    "        train_images.append(img_x)\n",
    "    \n",
    "    train_images = np.array(train_images)\n",
    "    pca = PCA(n_components=900).fit(train_images)\n",
    "    return pca\n",
    "    \n",
    "pca = generatePCA(labels_folder + train_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 30, 30])\n",
      "tensor([[[ 8.6343e+03, -4.7154e+03, -1.5083e+03, -1.0609e+03, -6.9808e+02,\n",
      "           2.2038e+01,  1.7968e+03, -1.5644e+03,  3.7659e+02, -2.7346e+02,\n",
      "          -9.7788e+02,  3.6708e+02, -1.5190e+02, -2.5441e+03, -5.5122e+02,\n",
      "          -1.3322e+03,  5.0740e+02, -1.4411e+02, -7.9145e+02, -4.6668e+02,\n",
      "           1.0706e+03,  1.9249e+02,  4.2524e+02,  1.8133e+02,  4.1831e+01,\n",
      "          -1.1888e+02,  1.1383e+03, -8.7304e+01, -1.7899e+03, -1.6369e+02],\n",
      "         [ 3.8242e+02,  3.5686e+02,  9.7100e+02,  5.9472e+02,  6.1771e+02,\n",
      "           1.0808e+03,  4.1833e+02, -2.3994e+02,  2.7257e+02, -2.1170e+03,\n",
      "          -7.0386e+02,  5.5099e+02, -2.0554e+02,  2.4663e+02,  3.5465e+02,\n",
      "           6.6649e+02,  2.5353e+01, -7.9874e+02, -3.6337e+02,  2.1260e+02,\n",
      "          -3.0372e+02, -2.7911e+02,  6.7331e+02, -8.8022e+02,  1.3823e+03,\n",
      "          -3.7869e+02,  9.6214e+02, -8.1501e+01,  4.6475e+02, -2.3279e+02],\n",
      "         [ 1.7028e+03,  1.9350e+02,  7.3971e+02, -1.5934e+02,  3.6627e+02,\n",
      "          -4.9539e+02, -5.9357e+02, -4.3453e+02, -2.2270e+02,  3.6365e+02,\n",
      "          -1.1539e+03,  1.5026e+02,  4.4687e+02, -2.3164e+02,  5.4902e+02,\n",
      "           9.0875e+02, -3.5570e+02, -7.0692e+02,  8.6149e+02, -6.2248e+02,\n",
      "          -1.9426e+02,  4.2921e+02, -6.0404e+02,  7.4255e+02, -1.3513e+03,\n",
      "           2.6530e+02,  2.4835e+02, -7.9430e+02,  5.4480e+02,  9.8387e+02],\n",
      "         [-4.4572e+02,  2.8197e+02, -9.5317e+01, -5.4843e+01,  1.0497e+03,\n",
      "          -1.8331e+02,  7.1713e+02,  3.6232e+02, -3.7291e+02,  3.0707e+02,\n",
      "           2.9083e+02, -4.5166e+02,  1.0149e+02, -1.0283e+02, -1.0450e+03,\n",
      "          -9.6700e+02, -3.1160e+02,  6.7460e+02, -1.3413e+03, -2.3341e+02,\n",
      "           3.9756e+02,  2.4026e+02, -1.0705e+03,  1.2121e+02, -1.3943e+02,\n",
      "           2.4529e+02,  8.0028e+02, -1.7240e+03, -2.2738e+02,  2.2721e+02],\n",
      "         [-1.1587e+03, -2.4987e+02, -6.7502e+02, -2.8448e+02, -1.5880e+01,\n",
      "          -4.2546e+02, -1.3309e+03,  3.4283e+02, -1.3231e+03, -1.5724e+03,\n",
      "           2.8986e+02,  4.5690e+02, -8.2010e+02,  6.2884e+02, -3.7221e+02,\n",
      "          -8.4429e+02,  2.8018e+02, -1.4957e+02, -3.9336e+02,  3.1124e+02,\n",
      "          -5.0898e+02, -1.1087e+02, -5.4826e+02, -6.2854e+01,  4.9666e+02,\n",
      "           2.8082e+01,  1.1365e+03, -4.6919e+02,  3.7983e+02, -4.3458e+02],\n",
      "         [ 9.3118e+00,  1.4589e+02, -4.2161e+02,  2.8074e+02, -7.9578e+02,\n",
      "           1.4179e+03, -1.1286e+03,  2.9409e+02,  9.4521e+02, -1.2643e+03,\n",
      "          -8.6124e+00, -4.9440e+02, -3.8399e+02,  2.2492e+02, -1.2227e+02,\n",
      "          -9.9273e+02,  6.3948e+02,  2.7160e+02, -1.2001e+02,  2.2662e+02,\n",
      "           1.4624e+03,  8.0845e+01, -1.1661e+03,  1.2690e+02, -2.2952e+02,\n",
      "           2.3038e+02,  3.1581e+02, -4.8779e+02, -7.6985e+01,  5.7606e+02],\n",
      "         [ 6.7098e+02,  5.7720e+01,  1.1024e+03,  6.7815e+02, -3.0999e+02,\n",
      "           6.9388e+01,  7.8106e+02, -4.9039e+02, -7.5522e+01,  1.1872e+02,\n",
      "           3.2845e+02,  1.7463e+02, -8.2970e+02,  4.9828e+02, -3.1672e+02,\n",
      "           2.1518e+02,  4.0522e+02, -2.1994e+02, -7.8115e+02, -5.4706e+02,\n",
      "          -1.1098e+03, -3.6556e+02,  7.1601e+00,  6.8218e+02,  3.6028e+02,\n",
      "          -8.3575e+01,  8.6646e+02,  6.0968e+01, -4.3797e+02, -3.2812e+02],\n",
      "         [ 1.2718e+02,  6.9916e+02, -4.5865e+02, -9.1615e+01, -3.9226e+02,\n",
      "           4.9149e+02, -9.5665e+02, -1.6924e+02, -7.5965e+02,  5.9637e+02,\n",
      "           3.4824e+02,  3.8532e+02,  8.1041e+00,  8.1665e+01, -3.4499e+02,\n",
      "           1.7192e+02, -1.0414e+03, -4.6353e+02, -5.6052e+01, -1.1858e+02,\n",
      "           2.4171e+02,  8.1930e+02, -7.0336e+02, -2.0942e+02,  2.2894e+02,\n",
      "           2.0693e+02, -2.9942e+02,  7.7270e+02,  1.3465e+02,  8.6797e+02],\n",
      "         [ 7.0136e+02, -2.2356e+02,  2.4371e+02,  3.4051e+02, -3.0764e+02,\n",
      "          -8.3322e+02,  1.9199e+02,  6.2331e+02,  4.7880e+02,  1.0804e+03,\n",
      "          -1.3197e+01,  1.2410e+02, -8.6523e+02, -2.7381e+02, -8.2916e+02,\n",
      "           4.2054e+02,  1.2342e+02, -5.0312e+02, -3.0712e+02,  2.8293e+02,\n",
      "           3.0470e+01, -3.9970e+02,  3.4285e+02, -2.4478e+02, -2.5718e+02,\n",
      "          -2.5238e+02, -4.3057e+02,  4.2796e+02,  1.0007e+02, -1.1633e+02],\n",
      "         [-4.1055e+02,  2.3263e+02,  5.6760e+01,  1.2012e+02, -4.3673e+02,\n",
      "          -2.5558e+02, -3.2486e+02, -1.2732e+02, -6.7734e+02, -7.9590e+01,\n",
      "           7.8607e+02, -8.9059e+02,  1.5387e+02, -7.7754e+02, -7.3469e+02,\n",
      "           1.6905e+01, -1.3712e+03, -7.1274e+02, -4.4664e+02, -8.9826e+02,\n",
      "          -2.4052e+02,  9.5255e+02, -4.0057e+01, -1.8980e+02,  4.0188e+02,\n",
      "           5.4160e+02,  1.6434e+02,  4.7355e+02,  1.0034e+02, -3.3101e+02],\n",
      "         [ 4.0979e+02,  7.7049e+01, -4.0502e+02,  5.6617e+02, -5.3210e+01,\n",
      "          -1.3930e+02, -1.9122e+02,  3.9323e+02,  2.5528e+02,  1.0136e+03,\n",
      "          -3.3438e+02,  2.6057e+02, -1.2147e+02, -9.7469e+00, -4.1524e+02,\n",
      "           5.3620e-01, -3.2306e+02,  7.0489e+01,  9.3983e+02, -6.4668e+02,\n",
      "           6.0055e+02,  2.7291e+01, -4.9168e+02, -6.6847e+01,  8.6766e+01,\n",
      "           9.0697e+02, -4.0208e+02, -1.0338e+02,  1.1434e+03, -1.6689e+02],\n",
      "         [-5.5440e+02, -1.2421e+02, -2.6123e+02, -1.1989e+02, -7.4355e+02,\n",
      "          -8.5492e+01, -4.6125e+02, -2.5848e+02, -2.7398e+02,  5.9030e+02,\n",
      "           5.3807e+02,  3.2226e+02, -3.1957e+02,  1.5903e+02, -7.7723e+01,\n",
      "           5.7600e+02, -1.9482e+02, -2.7319e+02, -2.2951e+02, -1.4956e+02,\n",
      "           6.3560e+02, -6.1744e+02,  4.2390e+02, -2.8504e+02, -2.3643e+02,\n",
      "           1.7740e+02,  3.8248e+02,  3.1576e+02, -5.2215e+02,  4.4724e+01],\n",
      "         [-4.4901e+02,  1.6943e+02,  7.1415e+02,  1.2606e+02, -1.8807e+02,\n",
      "           3.1353e+02, -7.8159e+00,  5.4135e+02, -5.1700e+00, -1.2968e+02,\n",
      "           8.6727e+01,  5.8063e+01, -4.9896e+02, -8.0528e+01,  5.4387e+02,\n",
      "           5.2709e+02,  4.6671e+01,  1.0764e+02,  1.0757e+02,  2.9485e+02,\n",
      "          -1.0343e+01, -5.5252e+02,  5.6588e+02, -3.3015e+02,  5.3646e+02,\n",
      "          -2.8191e+02, -3.8225e+02, -5.0910e+02,  1.2792e+02, -2.1689e+02],\n",
      "         [-2.2240e+02,  2.3208e+02,  4.6433e+02,  7.1284e+01,  2.7822e+02,\n",
      "           3.7871e+02, -2.5204e+02,  6.8378e+01, -5.0324e+02, -7.7873e+01,\n",
      "          -6.9017e+01, -2.8142e+02, -6.2004e+02, -2.3144e+02, -1.5566e+02,\n",
      "           1.3933e+02, -4.9891e+02,  6.2483e+02,  2.0565e+02,  1.3749e+02,\n",
      "          -2.5300e+02, -5.5403e+02, -1.9574e+02, -1.9437e+02,  1.0177e+03,\n",
      "          -4.1806e+02,  4.0583e+02,  5.0255e+02, -6.8528e+02,  4.4678e+02],\n",
      "         [ 6.7167e+02,  1.2977e+02, -1.2854e+02, -9.1767e+01, -3.4191e+02,\n",
      "          -6.5281e+02, -2.3448e+02, -1.7179e+02, -4.6631e+02,  8.7486e+01,\n",
      "          -4.6334e+02, -4.2415e+02, -1.4181e+01, -2.3023e+02,  1.3548e+02,\n",
      "           4.9378e+02, -1.2974e+02, -1.8577e+02,  2.3684e+02,  4.6429e+02,\n",
      "          -1.1353e+01, -7.7098e+02,  6.3753e+02, -5.1029e+02,  4.9314e+01,\n",
      "           7.1330e+02, -8.1988e+02,  2.8940e+02,  4.3001e+02, -3.0529e+02],\n",
      "         [-2.7071e+02,  2.6520e+02, -3.5018e+02, -2.5372e+02, -5.0946e+02,\n",
      "          -4.1894e+02, -1.6880e+02,  1.8002e+02,  2.6335e+02, -3.5559e+02,\n",
      "          -8.8995e+02, -6.5757e+01,  5.3875e+02, -1.4705e+02, -2.3609e+02,\n",
      "           1.2742e+02,  6.9287e+02, -7.8664e+02, -4.3266e+02, -8.7210e+01,\n",
      "           2.6476e+02,  1.5300e+01,  6.0917e+02, -8.5537e+02,  5.5952e+02,\n",
      "           2.0823e+02, -2.5002e+02, -4.2382e+02,  5.0110e+02,  1.0345e+02],\n",
      "         [-3.7422e+02,  1.6100e+02,  2.5539e+02,  1.4669e+00,  6.0864e+01,\n",
      "          -2.9817e+02, -5.4213e+02, -6.3492e+01,  6.8888e+02,  2.8783e+02,\n",
      "          -4.8456e+02,  5.5547e+02,  1.8137e+01,  4.3755e+02,  6.7328e+02,\n",
      "          -6.6120e+02, -1.5034e+02, -4.7864e+02, -7.5630e+02, -3.6219e+02,\n",
      "          -7.0085e+01,  5.8518e+02, -1.9159e+01, -1.1085e+02,  8.7432e+01,\n",
      "           6.6973e+02,  1.1476e+02, -2.8518e+02,  6.2652e+00,  5.1231e+01],\n",
      "         [-3.1069e+02,  2.0590e+02, -6.2606e+02, -5.5408e+01,  6.4709e+01,\n",
      "           6.4364e+02, -2.8232e+02, -3.9394e+02, -2.9624e+02,  1.9315e+02,\n",
      "          -5.5779e+01, -1.3956e+02,  2.0634e+02, -3.8318e+01,  2.6612e+02,\n",
      "          -4.8624e+02, -4.0431e+02, -8.1370e+02,  3.6745e+02,  4.8890e+02,\n",
      "           1.8712e+01,  2.5338e+02, -1.4235e+02,  5.9710e+02,  4.2366e+01,\n",
      "           3.2652e+02, -2.7176e+01, -3.0504e+02,  3.6918e+02, -5.9741e+01],\n",
      "         [-3.7904e+00, -1.3900e+01, -6.6034e+01, -9.2481e+01,  9.3039e+01,\n",
      "           1.5431e+02,  9.8750e+02,  4.4197e+02, -3.1510e+02,  2.8560e+02,\n",
      "          -1.6593e+02, -4.6295e+02,  9.3894e+01, -8.5889e+02,  2.0179e+02,\n",
      "           6.5189e+01,  1.0189e+01,  1.1846e+02, -2.0662e+02,  2.9148e+02,\n",
      "           5.0650e+02,  1.1269e+01, -3.3618e+02,  3.3004e+02,  2.3943e+02,\n",
      "          -5.8186e+02, -1.9619e+02,  4.4427e+01, -6.2214e+02,  5.6713e+02],\n",
      "         [-1.6161e+02,  6.8299e+02, -8.8899e+01,  2.2756e+02, -1.1162e+03,\n",
      "          -5.1062e+02,  3.1328e+02,  2.0137e+02,  6.3907e+01, -1.7343e+02,\n",
      "           8.1365e+02, -2.6405e+02, -1.0116e+02, -5.4414e+02,  1.2688e+01,\n",
      "          -1.6129e+02,  3.7881e+02, -3.1064e+02, -6.6453e+01,  2.6583e+02,\n",
      "          -7.7698e+02, -4.3977e+02,  1.4065e+02,  5.1221e+01, -1.5276e+02,\n",
      "          -3.8932e+02, -9.3139e+02, -5.0678e+02,  1.4622e+02, -4.0236e+01],\n",
      "         [-8.4021e+02, -1.7056e+02,  8.1837e+01,  2.5220e+02, -8.2525e+01,\n",
      "           9.6226e+01,  7.3359e+02,  1.6217e+02,  3.5767e+01, -2.8605e+02,\n",
      "          -8.0826e+02,  4.6098e+02, -4.0534e+02,  1.2524e+02, -3.2341e+01,\n",
      "          -4.8747e+02, -2.0118e+02,  6.7499e+02, -3.3781e+02, -3.6998e+02,\n",
      "           1.3614e+02, -5.8935e+02,  3.6539e+02, -1.6569e+02, -4.1345e+02,\n",
      "           4.4086e+02, -2.9019e+02,  7.0861e+02,  5.9716e+01,  1.2097e+02],\n",
      "         [ 3.9234e+02,  4.4797e+02, -1.3298e+02, -4.4641e+01, -1.8117e+02,\n",
      "           4.7101e+02, -1.7056e+02,  2.6708e+00, -4.2449e+02, -2.9422e+02,\n",
      "          -4.3057e+02,  5.0645e+01, -5.2602e+02,  4.2523e+02,  1.5656e+01,\n",
      "           1.8831e+02,  3.6551e+02,  5.8858e+01,  2.3073e+02,  3.9403e+02,\n",
      "          -2.0663e+02, -2.0709e+01,  2.2605e+02, -7.1423e+01,  3.1388e+02,\n",
      "          -3.4124e+02,  7.2621e+02,  9.6090e+02,  5.7138e+02, -6.6187e+01],\n",
      "         [-1.5369e+02,  2.5513e+02,  4.4426e+01, -3.2088e+02,  7.8729e+01,\n",
      "          -1.9663e+02,  3.2393e+02,  5.8484e+01,  6.1109e+02, -4.3934e+02,\n",
      "          -3.9243e+02,  1.4568e+02, -1.9987e+02,  2.1578e+02,  8.8713e+01,\n",
      "           1.8710e+02,  2.2361e+02, -2.2028e+01,  2.0220e+01,  9.8717e+00,\n",
      "          -7.1773e+01, -3.3511e+02,  9.3243e+01, -1.9236e+01, -6.5250e+02,\n",
      "           3.7191e+02, -5.9490e+02, -1.4239e+02,  7.4601e+01,  2.8530e+02],\n",
      "         [ 2.2037e+01,  1.7529e+02, -7.1389e+02,  8.5090e+01,  3.8282e+02,\n",
      "          -4.4312e+02,  3.3510e+01,  3.2132e+02,  6.1256e+02,  9.0466e+01,\n",
      "           1.1177e+02,  5.6136e+02,  3.4542e+02,  6.8261e+02,  5.0541e+02,\n",
      "           2.9058e+02, -3.6144e+02,  5.5526e+01,  4.2514e+02,  1.4823e+02,\n",
      "          -1.1395e+02,  4.1113e+02, -2.1875e+02, -7.6827e-01, -5.4249e+02,\n",
      "          -2.2493e+01,  7.0338e+02,  1.0349e+02,  4.0715e+02,  1.1651e+02],\n",
      "         [ 2.5575e+02, -2.4374e+02, -4.5833e+02, -2.0730e+02, -2.5893e+02,\n",
      "           3.0404e+02, -7.5241e+01, -6.1097e+02,  3.5079e+02,  8.3480e+01,\n",
      "          -4.4720e+02,  1.4489e+02, -3.3841e+02,  2.1137e+02,  6.9175e+01,\n",
      "          -4.1448e+02, -2.1479e+02, -2.5130e+02,  9.1851e-01, -6.7779e+01,\n",
      "          -6.7714e+01,  2.2981e+02, -7.6581e+02, -4.0458e+02, -8.7957e+01,\n",
      "          -3.3333e+02, -2.4605e+00,  1.6583e+02, -6.2146e+01, -4.4500e+01],\n",
      "         [-4.3404e+02,  1.0629e+03,  5.4854e+01, -2.4916e+02,  3.5351e+02,\n",
      "          -1.5192e+01, -6.3283e+01, -1.7846e+02, -2.8533e+01,  2.9299e+02,\n",
      "           1.4143e+02, -1.2529e+02, -2.9283e+02, -6.2461e+02,  2.5561e+02,\n",
      "          -1.2582e+02, -5.2997e+02, -3.8240e+02, -3.2654e+02,  4.2737e+02,\n",
      "          -3.6329e+01,  9.8533e+01,  4.5345e+02,  7.0176e+01,  1.3913e+02,\n",
      "          -5.3054e+02, -4.0210e+02,  1.5887e+01,  2.3973e+02, -1.9895e+02],\n",
      "         [ 3.6529e+01,  4.2479e+02,  6.1283e+02, -1.5655e+02, -3.3045e+02,\n",
      "           2.1772e+02, -4.9229e+02, -9.0280e+01, -1.0658e+02, -5.5553e+02,\n",
      "           9.3007e+02, -6.7322e+01, -3.3336e+02,  2.9102e+02, -4.5942e+02,\n",
      "           4.8572e+02,  1.5328e+02, -3.4215e+02,  3.3260e+02, -7.8261e+01,\n",
      "          -3.4690e+02, -2.1656e+02,  5.4950e+01,  4.2196e+02, -6.7144e+02,\n",
      "          -1.3089e+01,  2.8391e+02, -5.1395e+01,  1.3704e+01,  6.7134e+02],\n",
      "         [-3.5670e+02,  8.5017e+01,  2.8837e+02,  6.4604e+00, -7.0823e+00,\n",
      "           7.0893e+00,  1.2255e+02, -3.8848e+02,  5.1994e+02, -4.0878e+02,\n",
      "           1.0212e+02,  2.4413e+02, -7.4378e+01, -1.0389e+02, -2.7117e+02,\n",
      "           6.3606e+01,  4.5440e+01, -9.5831e+01,  3.4844e+01, -4.3513e+02,\n",
      "          -2.0182e+02,  2.2768e+02,  3.2956e+02, -2.0099e+01,  5.3919e+01,\n",
      "          -9.2049e+00,  3.2522e+02,  6.3445e-01, -4.3195e+02, -9.2987e+00],\n",
      "         [ 6.9312e+01, -1.3380e+02, -5.0943e+02,  2.1667e+02,  1.8124e+02,\n",
      "           3.3069e+02, -2.6411e+02, -2.3593e+02, -6.3775e+02,  6.4765e+02,\n",
      "           4.6077e+02,  3.7879e+01, -2.1237e+02, -1.2523e+02, -1.4040e+02,\n",
      "           1.7169e+02, -2.8469e+02, -2.2017e+01,  2.1686e+02,  1.2939e+02,\n",
      "           1.3489e+01, -1.1420e+01,  1.5092e+02, -5.9440e+01, -6.9580e+01,\n",
      "           1.6163e+02,  3.3843e+02,  2.0707e+02, -1.8677e+02, -2.6054e+01],\n",
      "         [ 1.0918e+02,  5.6716e+02,  3.1711e+02, -5.4042e+01,  4.7730e+02,\n",
      "          -4.8967e+02, -2.6328e+02,  5.9825e+02, -1.1878e+02, -1.2862e+02,\n",
      "           2.2558e+02, -3.8342e+02,  4.4599e+01,  6.0744e+02,  2.8856e+02,\n",
      "          -7.4307e+01,  2.4302e+02, -2.5352e+02, -4.4902e+02, -3.5748e+02,\n",
      "          -2.8905e+01, -5.2546e+02, -9.7050e+01, -1.4394e+02, -3.3650e+01,\n",
      "           4.4333e+01,  5.4200e+01, -1.1745e+02, -1.7908e+01,  1.0430e+02]]],\n",
      "       dtype=torch.float64)\n",
      "5038\n",
      "1680\n"
     ]
    }
   ],
   "source": [
    "csv_path = [labels_folder+\"train_subset0.csv\", labels_folder+\"train_subset1.csv\", \n",
    "            labels_folder+\"train_subset2.csv\", labels_folder+\"train_subset3.csv\", labels_folder+\"train_subset4.csv\"]\n",
    "test_csv_path = [labels_folder+\"val_subset0.csv\", labels_folder+\"val_subset1.csv\", \n",
    "            labels_folder+\"val_subset2.csv\", labels_folder+\"val_subset3.csv\", labels_folder+\"val_subset4.csv\"]\n",
    "\n",
    "\n",
    "train_data= DatasetFromCSV([labels_folder + train_sets[0]],transform,pca)\n",
    "test_data = DatasetFromCSV([labels_folder + test_sets[0]],transform,pca)\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size)\n",
    " \n",
    "img,lab = next(iter(train_loader))\n",
    "print(img.shape)\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, output_dim)\n",
    "        #self.linear2 = nn.Linear(4096, 256)\n",
    "        #self.linear3 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        # out = nn.functional.relu(out)\n",
    "        #out = self.linear2(out)\n",
    "        # out = nn.functional.relu(out)\n",
    "        #out = self.linear3(out)\n",
    "        # out = nn.functional.relu(out)\n",
    "        return out\n",
    "\n",
    "input_dim = 900\n",
    "output_dim = 8\n",
    "epochs = 15 * 2\n",
    "lr_rate = 0.001\n",
    "_lamda = 1.2\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "print(use_gpu)\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Finish 1 epoch, Loss: 8357.995620, Acc: 0.396983\n",
      "tensor(354, device='cuda:0') 1680\n",
      "accuracy of the model 21.07\n",
      "epoch 2\n",
      "Finish 2 epoch, Loss: 8226.928617, Acc: 0.406511\n",
      "tensor(351, device='cuda:0') 1680\n",
      "accuracy of the model 20.89\n",
      "epoch 3\n",
      "Finish 3 epoch, Loss: 8478.939410, Acc: 0.401350\n",
      "tensor(341, device='cuda:0') 1680\n",
      "accuracy of the model 20.30\n",
      "epoch 4\n",
      "Finish 4 epoch, Loss: 8308.375313, Acc: 0.410282\n",
      "tensor(342, device='cuda:0') 1680\n",
      "accuracy of the model 20.36\n",
      "epoch 5\n",
      "Finish 5 epoch, Loss: 8537.386941, Acc: 0.393609\n",
      "tensor(341, device='cuda:0') 1680\n",
      "accuracy of the model 20.30\n",
      "epoch 6\n",
      "Finish 6 epoch, Loss: 8270.991356, Acc: 0.412267\n",
      "tensor(320, device='cuda:0') 1680\n",
      "accuracy of the model 19.05\n",
      "epoch 7\n",
      "Finish 7 epoch, Loss: 8418.574986, Acc: 0.401350\n",
      "tensor(341, device='cuda:0') 1680\n",
      "accuracy of the model 20.30\n",
      "epoch 8\n",
      "Finish 8 epoch, Loss: 8499.276871, Acc: 0.401548\n",
      "tensor(338, device='cuda:0') 1680\n",
      "accuracy of the model 20.12\n",
      "epoch 9\n",
      "Finish 9 epoch, Loss: 8451.901233, Acc: 0.403533\n",
      "tensor(333, device='cuda:0') 1680\n",
      "accuracy of the model 19.82\n",
      "epoch 10\n",
      "Finish 10 epoch, Loss: 8285.968993, Acc: 0.411671\n",
      "tensor(307, device='cuda:0') 1680\n",
      "accuracy of the model 18.27\n",
      "epoch 11\n",
      "Finish 11 epoch, Loss: 8353.678090, Acc: 0.414053\n",
      "tensor(326, device='cuda:0') 1680\n",
      "accuracy of the model 19.40\n",
      "epoch 12\n",
      "Finish 12 epoch, Loss: 8405.976805, Acc: 0.401548\n",
      "tensor(334, device='cuda:0') 1680\n",
      "accuracy of the model 19.88\n",
      "epoch 13\n",
      "Finish 13 epoch, Loss: 8349.681614, Acc: 0.409091\n",
      "tensor(357, device='cuda:0') 1680\n",
      "accuracy of the model 21.25\n",
      "epoch 14\n",
      "Finish 14 epoch, Loss: 8474.937900, Acc: 0.408297\n",
      "tensor(337, device='cuda:0') 1680\n",
      "accuracy of the model 20.06\n",
      "epoch 15\n",
      "Finish 15 epoch, Loss: 8366.511751, Acc: 0.416038\n",
      "tensor(326, device='cuda:0') 1680\n",
      "accuracy of the model 19.40\n",
      "epoch 16\n",
      "Finish 16 epoch, Loss: 8433.986927, Acc: 0.400556\n",
      "tensor(340, device='cuda:0') 1680\n",
      "accuracy of the model 20.24\n",
      "epoch 17\n",
      "Finish 17 epoch, Loss: 8413.449110, Acc: 0.415443\n",
      "tensor(370, device='cuda:0') 1680\n",
      "accuracy of the model 22.02\n",
      "epoch 18\n",
      "Finish 18 epoch, Loss: 8332.983098, Acc: 0.407503\n",
      "tensor(352, device='cuda:0') 1680\n",
      "accuracy of the model 20.95\n",
      "epoch 19\n",
      "Finish 19 epoch, Loss: 8293.002520, Acc: 0.415443\n",
      "tensor(313, device='cuda:0') 1680\n",
      "accuracy of the model 18.63\n",
      "epoch 20\n",
      "Finish 20 epoch, Loss: 8477.144067, Acc: 0.408694\n",
      "tensor(326, device='cuda:0') 1680\n",
      "accuracy of the model 19.40\n",
      "epoch 21\n",
      "Finish 21 epoch, Loss: 8470.024290, Acc: 0.409686\n",
      "tensor(323, device='cuda:0') 1680\n",
      "accuracy of the model 19.23\n",
      "epoch 22\n",
      "Finish 22 epoch, Loss: 8325.384144, Acc: 0.416634\n",
      "tensor(335, device='cuda:0') 1680\n",
      "accuracy of the model 19.94\n",
      "epoch 23\n",
      "Finish 23 epoch, Loss: 8377.818957, Acc: 0.405717\n",
      "tensor(337, device='cuda:0') 1680\n",
      "accuracy of the model 20.06\n",
      "epoch 24\n",
      "Finish 24 epoch, Loss: 8309.419160, Acc: 0.420206\n",
      "tensor(308, device='cuda:0') 1680\n",
      "accuracy of the model 18.33\n",
      "epoch 25\n",
      "Finish 25 epoch, Loss: 8311.676363, Acc: 0.420206\n",
      "tensor(341, device='cuda:0') 1680\n",
      "accuracy of the model 20.30\n",
      "epoch 26\n",
      "Finish 26 epoch, Loss: 8453.403614, Acc: 0.401548\n",
      "tensor(337, device='cuda:0') 1680\n",
      "accuracy of the model 20.06\n",
      "epoch 27\n",
      "Finish 27 epoch, Loss: 8544.022075, Acc: 0.413259\n",
      "tensor(349, device='cuda:0') 1680\n",
      "accuracy of the model 20.77\n",
      "epoch 28\n",
      "Finish 28 epoch, Loss: 8473.384883, Acc: 0.410877\n",
      "tensor(349, device='cuda:0') 1680\n",
      "accuracy of the model 20.77\n",
      "epoch 29\n",
      "Finish 29 epoch, Loss: 8414.598310, Acc: 0.413855\n",
      "tensor(341, device='cuda:0') 1680\n",
      "accuracy of the model 20.30\n",
      "epoch 30\n",
      "Finish 30 epoch, Loss: 8314.710398, Acc: 0.416832\n",
      "tensor(362, device='cuda:0') 1680\n",
      "accuracy of the model 21.55\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(int(epochs)):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader): #利用enumerate取出一个可迭代对象的内容\n",
    "        images = images.view(-1, 900)\n",
    "        if use_gpu:\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        num_correct = (pred == labels).sum()\n",
    "        running_acc += num_correct.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        '''\n",
    "        if  i % 100 == 0:\n",
    "            print (model.parameters())\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, epochs, running_loss / (batch_size * (i+1)),\n",
    "                running_acc / (batch_size * (i+1))))\n",
    "        '''\n",
    "    \n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_data)), running_acc / (len(train_data))))\n",
    "    \n",
    "    # test the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.view(-1, 900) \n",
    "        if use_gpu:\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print(correct, total)\n",
    "    print('accuracy of the model %.2f' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.view(-1, 256 * 256) \n",
    "    if use_gpu:\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "    else:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    print (predicted)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print(correct, total)\n",
    "print('accuracy of the model %.2f' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

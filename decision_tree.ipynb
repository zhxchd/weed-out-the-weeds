{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieve Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np;\n",
    "\n",
    "raw_ds = tfds.load('deep_weeds', split=\"train\", as_supervised=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-process Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predicate(x, y):\n",
    "  return tf.not_equal(y, 8)\n",
    "\n",
    "full_ds = raw_ds.filter(predicate) # remove instances from negative class\n",
    "full_ds_size = full_ds.reduce(0, lambda x,_: x + 1).numpy()\n",
    "full_ds = full_ds.shuffle(full_ds_size) # shuffle dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# train_size = int(0.7 * full_ds_size)\n",
    "# test_size = int(0.3 * full_ds_size)\n",
    "\n",
    "train_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "\n",
    "train_ds = full_ds.take(train_size)\n",
    "test_ds = full_ds.skip(train_size)\n",
    "\n",
    "train_ds_numpy = tfds.as_numpy(train_ds)\n",
    "test_ds_numpy = tfds.as_numpy(test_ds)\n",
    "\n",
    "print(f'Total number of all instances = {full_ds_size}')\n",
    "print(f'Total number of training instances = {train_size}')\n",
    "print(f'Total number of testing instances = {test_size}')\n",
    "\n",
    "# TODO: Reduce dimension\n",
    "# TODO: Abstract function"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of all instances = 8403\n",
      "Total number of training instances = 1000\n",
      "Total number of testing instances = 1000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "for ex in train_ds_numpy:\n",
    "  pixels = ex[0] # 256 x 256 x 3 (RGB)\n",
    "  label = ex[1]\n",
    "  row = pixels.flatten()\n",
    "  train_X.append(row)\n",
    "  train_Y.append(label)\n",
    "print(f'Sample train_X: {train_X[0]}')\n",
    "print(f'Sample train_Y: {train_Y[0]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample train_X: [255 243 236 ... 124 139 134]\n",
      "Sample train_Y: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "for ex in test_ds_numpy:\n",
    "  pixels = ex[0] # 256 x 256 x 3 (RGB)\n",
    "  label = ex[1]\n",
    "  row = pixels.flatten()\n",
    "  test_X.append(row)\n",
    "  test_Y.append(label)\n",
    "print(f'Sample test_X: {test_X[0]}')\n",
    "print(f'Sample test_Y: {test_Y[0]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-10 01:41:56.511766: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 6760 of 8403\n",
      "2021-10-10 01:41:58.675614: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample test_X: [145 152 160 ...  71 144  89]\n",
      "Sample test_Y: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model (Decision Tree)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# ~170s for 1000 training instances max_depth=None\n",
    "\n",
    "# ~89.5s for 1000 training instances max_depth=5\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(train_X, train_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# 0.29 ~85.3s for 1000 training instances max_depth=None\n",
    "\n",
    "# 0.216 ~68.4s for 1000 training instances max_depth=5\n",
    "\n",
    "correct_prediction_count = 0\n",
    "predicted_test_Y = clf.predict(test_X)\n",
    "for i in range(test_size):\n",
    "  if predicted_test_Y[i] == test_Y[i]:\n",
    "    correct_prediction_count += 1\n",
    "accuracy = correct_prediction_count / test_size\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.216\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
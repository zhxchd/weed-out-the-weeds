{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np;\n",
    "\n",
    "raw_ds = tfds.load('deep_weeds', split=\"train\", as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_class_filter(x, y):\n",
    "  return tf.not_equal(y, 8)\n",
    "\n",
    "def rgb_to_grayscale_map(x, y):\n",
    "  return (tf.reduce_mean(x, 2), y)\n",
    "\n",
    "def downsampling(x, y):\n",
    "  return (tf.image.resize(x, [64, 64]), y)\n",
    "\n",
    "full_ds = raw_ds.filter(negative_class_filter) # remove instances from negative class\n",
    "full_ds_size = full_ds.reduce(0, lambda x,_: x + 1).numpy()\n",
    "full_ds = full_ds.shuffle(full_ds_size) # shuffle dataset\n",
    "full_ds = full_ds.map(downsampling)\n",
    "# full_ds = full_ds.map(rgb_to_grayscale_map) # convert to grayscale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all instances = 8403\n",
      "Total number of used instances = 2000\n",
      "Total number of training instances = 1000\n",
      "Total number of testing instances = 1000\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * full_ds_size)\n",
    "test_size = int(0.3 * full_ds_size)\n",
    "\n",
    "# train_size = 1000\n",
    "# test_size = 1000\n",
    "used_size = train_size + test_size\n",
    "\n",
    "used_ds = full_ds.take(used_size)\n",
    "\n",
    "train_ds = used_ds.take(train_size)\n",
    "test_ds = used_ds.skip(train_size)\n",
    "\n",
    "train_ds_numpy = tfds.as_numpy(train_ds)\n",
    "test_ds_numpy = tfds.as_numpy(test_ds)\n",
    "\n",
    "print(f'Total number of all instances = {full_ds_size}')\n",
    "print(f'Total number of used instances = {used_size}')\n",
    "print(f'Total number of training instances = {train_size}')\n",
    "print(f'Total number of testing instances = {test_size}')\n",
    "\n",
    "# TODO: Reduce dimension\n",
    "# TODO: Abstract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train_X: [123.25 119.25 120.5  ... 205.75 204.   209.  ]\n",
      "Dimension of train_X: 12288\n",
      "Sample train_Y: 5\n",
      "Sample test_X: [107.75  80.75  92.25 ... 127.   102.25 114.  ]\n",
      "Dimension of test_X: 12288\n",
      "Sample test_Y: 0\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "for ex in train_ds_numpy:\n",
    "  x = ex[0].flatten()\n",
    "  y = ex[1]\n",
    "  train_X.append(x)\n",
    "  train_Y.append(y)\n",
    "print(f'Sample train_X: {train_X[0]}')\n",
    "print(f'Dimension of train_X: {len(train_X[0])}')\n",
    "print(f'Sample train_Y: {train_Y[0]}')\n",
    "\n",
    "test_X = []\n",
    "test_Y = []\n",
    "for ex in test_ds_numpy:\n",
    "  x = ex[0].flatten()\n",
    "  y = ex[1]\n",
    "  test_X.append(x)\n",
    "  test_Y.append(y)\n",
    "print(f'Sample test_X: {test_X[0]}')\n",
    "print(f'Dimension of test_X: {len(test_X[0])}')\n",
    "print(f'Sample test_Y: {test_Y[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predicted_Y, actual_Y):\n",
    "  total_count = len(predicted_Y)\n",
    "  correct_count = 0\n",
    "  for i in range(total_count):\n",
    "    if predicted_Y[i] == actual_Y[i]:\n",
    "      correct_count += 1\n",
    "  accuracy = correct_count / total_count\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "\n",
    "def run_decision_tree(train_X, train_Y, test_X, test_Y, depth):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(train_X, train_Y)\n",
    "    predicted_Y = clf.predict(test_X)\n",
    "    accuracy = get_accuracy(predicted_Y, test_Y)\n",
    "    return accuracy\n",
    "\n",
    "def kfold_cross_validation(k, train_X, train_Y, depth):\n",
    "  print(f'Running {k}-fold cross validation for depth: {depth}')\n",
    "  k = 5\n",
    "  kf = KFold(n_splits=k)\n",
    "\n",
    "  accuracy_scores = []\n",
    "\n",
    "  for train_index, test_index in kf.split(train_X):\n",
    "    cf_train_X = [train_X[index] for index in train_index]\n",
    "    cf_train_Y = [train_Y[index] for index in train_index]\n",
    "    cf_test_X = [train_X[index] for index in test_index]\n",
    "    cf_test_Y = [train_Y[index] for index in test_index]\n",
    "    accuracy = run_decision_tree(cf_train_X, cf_train_Y, cf_test_X, cf_test_Y, depth)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Obtained split accuracy of: {accuracy}')\n",
    "\n",
    "  average_accuracy = sum(accuracy_scores) / k\n",
    "  print(f'Completed {k}-fold cross validation for depth: {depth}')\n",
    "  print(f'Obtained average accuracy of: {average_accuracy}')\n",
    "  return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation for depths: [3, 5]\n",
      "Running 5-fold cross validation for depth: 3\n",
      "Obtained split accuracy of: 0.18\n",
      "Obtained split accuracy of: 0.2\n",
      "Obtained split accuracy of: 0.135\n",
      "Obtained split accuracy of: 0.2\n",
      "Obtained split accuracy of: 0.205\n",
      "Completed 5-fold cross validation for depth: 3\n",
      "Obtained average accuracy of: 0.184\n",
      "Running 5-fold cross validation for depth: 5\n",
      "Obtained split accuracy of: 0.195\n",
      "Obtained split accuracy of: 0.165\n",
      "Obtained split accuracy of: 0.16\n",
      "Obtained split accuracy of: 0.18\n",
      "Obtained split accuracy of: 0.15\n",
      "Completed 5-fold cross validation for depth: 5\n",
      "Obtained average accuracy of: 0.16999999999999998\n",
      "Average scores for each depth: [0.184, 0.16999999999999998]\n",
      "Best depth: 3\n"
     ]
    }
   ],
   "source": [
    "def get_best_depth(depths):\n",
    "  accuracy_scores = []\n",
    "  k = 5\n",
    "  print(f'Running {k}-fold cross validation for depths: {depths}')\n",
    "  for depth in depths:\n",
    "    average_accuracy = kfold_cross_validation(k, train_X, train_Y, depth)\n",
    "    accuracy_scores.append(average_accuracy)\n",
    "\n",
    "  index = accuracy_scores.index(max(accuracy_scores))\n",
    "  print(f'Average scores for each depth: {accuracy_scores}')\n",
    "  print(f'Best depth: {depths[index]}')\n",
    "  return depths[index]\n",
    "\n",
    "depths = [4, 6, 8, 10, 12, 16, 18, 20]\n",
    "best_depth = get_best_depth(depths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained final accuracy of 0.191\n"
     ]
    }
   ],
   "source": [
    "final_accuracy = run_decision_tree(train_X, train_Y, test_X, test_Y, best_depth)\n",
    "print(f'Obtained final accuracy of {final_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

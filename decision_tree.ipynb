{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 11:39:59.813791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np;\n",
    "\n",
    "raw_ds = tfds.load('deep_weeds', split=\"train\", as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 11:40:03.985302: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "def negative_class_filter(x, y):\n",
    "  return tf.not_equal(y, 8)\n",
    "\n",
    "def rgb_to_grayscale_map(x, y):\n",
    "  return (tf.reduce_mean(x, 2), y)\n",
    "\n",
    "full_ds = raw_ds.filter(negative_class_filter) # remove instances from negative class\n",
    "full_ds_size = full_ds.reduce(0, lambda x,_: x + 1).numpy()\n",
    "full_ds = full_ds.shuffle(full_ds_size) # shuffle dataset\n",
    "full_ds = full_ds.map(rgb_to_grayscale_map) # convert to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all instances = 8403\n",
      "Total number of used instances = 8402\n",
      "Total number of training instances = 5882\n",
      "Total number of testing instances = 2520\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * full_ds_size)\n",
    "test_size = int(0.3 * full_ds_size)\n",
    "\n",
    "# train_size = 1000\n",
    "# test_size = 1000\n",
    "used_size = train_size + test_size\n",
    "\n",
    "used_ds = full_ds.take(used_size)\n",
    "\n",
    "train_ds = used_ds.take(train_size)\n",
    "test_ds = used_ds.skip(train_size)\n",
    "\n",
    "train_ds_numpy = tfds.as_numpy(train_ds)\n",
    "test_ds_numpy = tfds.as_numpy(test_ds)\n",
    "\n",
    "print(f'Total number of all instances = {full_ds_size}')\n",
    "print(f'Total number of used instances = {used_size}')\n",
    "print(f'Total number of training instances = {train_size}')\n",
    "print(f'Total number of testing instances = {test_size}')\n",
    "\n",
    "# TODO: Reduce dimension\n",
    "# TODO: Abstract function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predicted_Y, actual_Y):\n",
    "  total_count = len(predicted_Y)\n",
    "  correct_count = 0\n",
    "  for i in range(total_count):\n",
    "    if predicted_Y[i] == actual_Y[i]:\n",
    "      correct_count += 1\n",
    "  accuracy = correct_count / total_count\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train_X: [251 250 111 ...  10  17  18]\n",
      "Sample train_Y: 3\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "for ex in test_ds_numpy:\n",
    "  x = ex[0].flatten()\n",
    "  y = ex[1]\n",
    "  train_X.append(x)\n",
    "  train_Y.append(y)\n",
    "print(f'Sample train_X: {train_X[0]}')\n",
    "print(f'Sample train_Y: {train_Y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each fold: [0.16, 0.215, 0.19, 0.135, 0.16]\n",
      "Average accuracy: 0.172\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(train_X):\n",
    "  cf_train_X = [train_X[index] for index in train_index]\n",
    "  cf_train_Y = [train_Y[index] for index in train_index]\n",
    "  cf_test_X = [train_X[index] for index in test_index]\n",
    "  cf_test_Y = [train_Y[index] for index in test_index]\n",
    "  clf = tree.DecisionTreeClassifier()\n",
    "  clf = clf.fit(cf_train_X, cf_train_Y)\n",
    "  predicted_Y = clf.predict(cf_test_X)\n",
    "  accuracy = get_accuracy(predicted_Y, cf_test_Y)\n",
    "  accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / k\n",
    "print(f'Accuracy for each fold: {accuracy_scores}')\n",
    "print(f'Average accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ~170s for 1000 training instances max_depth=None RGB\n",
    "\n",
    "# ~42.2s for 1000 training instances max_depth=None Grayscale\n",
    "\n",
    "# ~89.5s for 1000 training instances max_depth=5 RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.29 ~85.3s for 1000 training instances max_depth=None RGB\n",
    "\n",
    "# 0.266 ~0.2s for 1000 training instances max_depth=None Grayscale\n",
    "\n",
    "# 0.216 ~68.4s for 1000 training instances max_depth=5 RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample test_X: [104  71  43 ... 197 248  45]\n",
      "Sample test_Y: 0\n"
     ]
    }
   ],
   "source": [
    "# test_X = []\n",
    "# test_Y = []\n",
    "# for ex in test_ds_numpy:\n",
    "#   x = ex[0].flatten() # 256 x 256 (Grayscale)\n",
    "#   y = ex[1]\n",
    "#   test_X.append(x)\n",
    "#   test_Y.append(y)\n",
    "# print(f'Sample test_X: {test_X[0]}')\n",
    "# print(f'Sample test_Y: {test_Y[0]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
